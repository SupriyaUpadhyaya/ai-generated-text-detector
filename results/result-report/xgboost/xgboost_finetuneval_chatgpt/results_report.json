{
    "Model Type": "xgboost",
    "Task": "finetuneAndEval",
    "Training Data": "chatgpt",
    "Data Type": "abstract",
    "New Line": "without",
    "Log Folder Name": "xgboost_finetuneval_chatgpt",
    "Title": "XGBoost Finetune and Evaluation - chatgpt",
    "percentage": null,
    "train": true,
    "Train input path": "data/without_n_preprocessed/arxiv_chatGPT_train.jsonl",
    "Test input path": "data/without_n_preprocessed/arxiv_chatGPT_test.jsonl",
    "Validation input path": "data/without_n_preprocessed/arxiv_chatGPT_val.jsonl",
    "Human text column name": "human_text",
    "Machine text column name": "machine_text",
    "log_path": "results/report/xgboost/xgboost_finetuneval_chatgpt/",
    "Training accuracy": 0.8458333333333333,
    "precision_score chatgpt_abstract_without": "0.8821362799263351",
    "F1 score chatgpt_abstract_without": "0.8381452318460193",
    "Accuracy Score chatgpt_abstract_without": "0.8458333333333333",
    "Recall Score chatgpt_abstract_without": "0.7983333333333333",
    "precision_score chatgpt_abstract_paraphrased_without": "0.8821362799263351",
    "F1 score chatgpt_abstract_paraphrased_without": "0.8381452318460193",
    "Accuracy Score chatgpt_abstract_paraphrased_without": "0.8458333333333333",
    "Recall Score chatgpt_abstract_paraphrased_without": "0.7983333333333333",
    "precision_score bloomz_abstract_without": "0.1568627450980392",
    "F1 score bloomz_abstract_without": "0.02457757296466974",
    "Accuracy Score bloomz_abstract_without": "0.4708333333333333",
    "Recall Score bloomz_abstract_without": "0.013333333333333334",
    "precision_score bloomz_abstract_paraphrased_without": "0.1568627450980392",
    "F1 score bloomz_abstract_paraphrased_without": "0.02457757296466974",
    "Accuracy Score bloomz_abstract_paraphrased_without": "0.4708333333333333",
    "Recall Score bloomz_abstract_paraphrased_without": "0.013333333333333334",
    "precision_score llama3_abstract_without": "0.6898954703832753",
    "F1 score llama3_abstract_without": "0.4464487034949267",
    "Accuracy Score llama3_abstract_without": "0.5908333333333333",
    "Recall Score llama3_abstract_without": "0.33",
    "precision_score cohere_abstract_without": "0.7589285714285714",
    "F1 score cohere_abstract_without": "0.23876404494382023",
    "Accuracy Score cohere_abstract_without": "0.5483333333333333",
    "Recall Score cohere_abstract_without": "0.14166666666666666",
    "precision_score davinci_abstract_without": "0.2875",
    "F1 score davinci_abstract_without": "0.12105263157894737",
    "Accuracy Score davinci_abstract_without": "0.44333333333333336",
    "Recall Score davinci_abstract_without": "0.07666666666666666",
    "precision_score flant5_abstract_without": "0.15950920245398773",
    "F1 score flant5_abstract_without": "0.06815203145478375",
    "Accuracy Score flant5_abstract_without": "0.4075",
    "Recall Score flant5_abstract_without": "0.043333333333333335",
    "precision_score llama3_ml_without": "0.4362745098039216",
    "F1 score llama3_ml_without": "0.22139303482587064",
    "Accuracy Score llama3_ml_without": "0.47833333333333333",
    "Recall Score llama3_ml_without": "0.14833333333333334",
    "precision_score bloomz_wiki_without": "0.5",
    "F1 score bloomz_wiki_without": "0.0033222591362126247",
    "Accuracy Score bloomz_wiki_without": "0.5",
    "Recall Score bloomz_wiki_without": "0.0016666666666666668",
    "precision_score chatgpt_wiki_without": "1.0",
    "F1 score chatgpt_wiki_without": "0.0",
    "Accuracy Score chatgpt_wiki_without": "0.5",
    "Recall Score chatgpt_wiki_without": "0.0",
    "precision_score cohere_wiki_without": "1.0",
    "F1 score cohere_wiki_without": "0.0",
    "Accuracy Score cohere_wiki_without": "0.5",
    "Recall Score cohere_wiki_without": "0.0",
    "precision_score davinci_wiki_without": "1.0",
    "F1 score davinci_wiki_without": "0.0",
    "Accuracy Score davinci_wiki_without": "0.5",
    "Recall Score davinci_wiki_without": "0.0",
    "precision_score chatgptBloomz_abstract_without": "0.8013856812933026",
    "F1 score chatgptBloomz_abstract_without": "0.42498469075321493",
    "Accuracy Score chatgptBloomz_abstract_without": "0.60875",
    "Recall Score chatgptBloomz_abstract_without": "0.2891666666666667",
    "precision_score bloomzWiki_abstract_without": "1.0",
    "F1 score bloomzWiki_abstract_without": "0.0016652789342214821",
    "Accuracy Score bloomzWiki_abstract_without": "0.5004166666666666",
    "Recall Score bloomzWiki_abstract_without": "0.0008333333333333334",
    "precision_score bloomzWikiML_abstract_without": "1.0",
    "F1 score bloomzWikiML_abstract_without": "0.001110494169905608",
    "Accuracy Score bloomzWikiML_abstract_without": "0.5002777777777778",
    "Recall Score bloomzWikiML_abstract_without": "0.0005555555555555556"
}