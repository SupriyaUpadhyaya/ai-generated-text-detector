{
    "Model Type": "xgboost",
    "Task": "finetuneAndEval",
    "Training Data": "bloomz",
    "Data Type": "wiki",
    "New Line": "without",
    "Log Folder Name": "xgboost_finetuneeval_bloomz_wiki",
    "Title": "XGBoost Finetune and Evaluation - bloomz wiki",
    "percentage": null,
    "train": true,
    "Train input path": "data/without_n_wiki_preprocessed/wikipedia_bloomz_train.jsonl",
    "Test input path": "data/without_n_wiki_preprocessed/wikipedia_bloomz_test.jsonl",
    "Validation input path": "data/without_n_wiki_preprocessed/wikipedia_bloomz_val.jsonl",
    "Human text column name": "text",
    "Machine text column name": "machine_abstract",
    "log_path": "results/report/xgboost/xgboost_finetuneeval_bloomz_wiki/",
    "Training accuracy": 0.8833333333333333,
    "precision_score chatgpt_abstract_without": "0.0",
    "F1 score chatgpt_abstract_without": "0.0",
    "Accuracy Score chatgpt_abstract_without": "0.49666666666666665",
    "Recall Score chatgpt_abstract_without": "0.0",
    "precision_score chatgpt_abstract_paraphrased_without": "0.0",
    "F1 score chatgpt_abstract_paraphrased_without": "0.0",
    "Accuracy Score chatgpt_abstract_paraphrased_without": "0.49666666666666665",
    "Recall Score chatgpt_abstract_paraphrased_without": "0.0",
    "precision_score bloomz_abstract_without": "0.782608695652174",
    "F1 score bloomz_abstract_without": "0.05778491171749599",
    "Accuracy Score bloomz_abstract_without": "0.5108333333333334",
    "Recall Score bloomz_abstract_without": "0.03",
    "precision_score bloomz_abstract_paraphrased_without": "0.782608695652174",
    "F1 score bloomz_abstract_paraphrased_without": "0.05778491171749599",
    "Accuracy Score bloomz_abstract_paraphrased_without": "0.5108333333333334",
    "Recall Score bloomz_abstract_paraphrased_without": "0.03",
    "precision_score llama3_abstract_without": "1.0",
    "F1 score llama3_abstract_without": "0.0",
    "Accuracy Score llama3_abstract_without": "0.5",
    "Recall Score llama3_abstract_without": "0.0",
    "precision_score cohere_abstract_without": "0.0",
    "F1 score cohere_abstract_without": "0.0",
    "Accuracy Score cohere_abstract_without": "0.49666666666666665",
    "Recall Score cohere_abstract_without": "0.0",
    "precision_score davinci_abstract_without": "0.6",
    "F1 score davinci_abstract_without": "0.009917355371900827",
    "Accuracy Score davinci_abstract_without": "0.5008333333333334",
    "Recall Score davinci_abstract_without": "0.005",
    "precision_score flant5_abstract_without": "0.5833333333333334",
    "F1 score flant5_abstract_without": "0.02287581699346405",
    "Accuracy Score flant5_abstract_without": "0.5016666666666667",
    "Recall Score flant5_abstract_without": "0.011666666666666667",
    "precision_score llama3_ml_without": "0.0",
    "F1 score llama3_ml_without": "0.0",
    "Accuracy Score llama3_ml_without": "0.49",
    "Recall Score llama3_ml_without": "0.0",
    "precision_score bloomz_wiki_without": "0.8560371517027864",
    "F1 score bloomz_wiki_without": "0.8876404494382022",
    "Accuracy Score bloomz_wiki_without": "0.8833333333333333",
    "Recall Score bloomz_wiki_without": "0.9216666666666666",
    "precision_score chatgpt_wiki_without": "0.0",
    "F1 score chatgpt_wiki_without": "0.0",
    "Accuracy Score chatgpt_wiki_without": "0.44991652754590983",
    "Recall Score chatgpt_wiki_without": "0.0",
    "precision_score cohere_wiki_without": "0.0",
    "F1 score cohere_wiki_without": "0.0",
    "Accuracy Score cohere_wiki_without": "0.4465811965811966",
    "Recall Score cohere_wiki_without": "0.0",
    "precision_score davinci_wiki_without": "0.012195121951219513",
    "F1 score davinci_wiki_without": "0.002932551319648094",
    "Accuracy Score davinci_wiki_without": "0.43333333333333335",
    "Recall Score davinci_wiki_without": "0.0016666666666666668",
    "precision_score chatgptBloomz_abstract_without": "0.6428571428571429",
    "F1 score chatgptBloomz_abstract_without": "0.029315960912052116",
    "Accuracy Score chatgptBloomz_abstract_without": "0.5033333333333333",
    "Recall Score chatgptBloomz_abstract_without": "0.015",
    "precision_score bloomzWiki_abstract_without": "0.8281786941580757",
    "F1 score bloomzWiki_abstract_without": "0.5409652076318743",
    "Accuracy Score bloomzWiki_abstract_without": "0.6591666666666667",
    "Recall Score bloomzWiki_abstract_without": "0.40166666666666667",
    "precision_score bloomzWikiML_abstract_without": "0.724812030075188",
    "F1 score bloomzWikiML_abstract_without": "0.39107505070993914",
    "Accuracy Score bloomzWikiML_abstract_without": "0.5830555555555555",
    "Recall Score bloomzWikiML_abstract_without": "0.2677777777777778"
}