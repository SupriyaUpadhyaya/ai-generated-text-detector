{
    "Model Type": "xgboost",
    "Task": "finetuneAndEval",
    "Training Data": "chatgpt",
    "Data Type": "wiki",
    "New Line": "without",
    "Log Folder Name": "xgboost_finetuneeval_chatgpt_wiki",
    "Title": "XGBoost Finetune and Evaluation - chatgpt wiki",
    "percentage": null,
    "train": true,
    "Train input path": "data/without_n_wiki_preprocessed/wikipedia_chatgpt_train.jsonl",
    "Test input path": "data/without_n_wiki_preprocessed/wikipedia_chatgpt_test.jsonl",
    "Validation input path": "data/without_n_wiki_preprocessed/wikipedia_chatgpt_val.jsonl",
    "Human text column name": "human_text",
    "Machine text column name": "machine_text",
    "log_path": "results/report/xgboost/xgboost_finetuneeval_chatgpt_wiki/",
    "Training accuracy": 0.9090150250417363,
    "precision_score chatgpt_abstract_without": "1.0",
    "F1 score chatgpt_abstract_without": "0.0",
    "Accuracy Score chatgpt_abstract_without": "0.5",
    "Recall Score chatgpt_abstract_without": "0.0",
    "precision_score chatgpt_abstract_paraphrased_without": "1.0",
    "F1 score chatgpt_abstract_paraphrased_without": "0.0",
    "Accuracy Score chatgpt_abstract_paraphrased_without": "0.5",
    "Recall Score chatgpt_abstract_paraphrased_without": "0.0",
    "precision_score bloomz_abstract_without": "1.0",
    "F1 score bloomz_abstract_without": "0.0",
    "Accuracy Score bloomz_abstract_without": "0.5",
    "Recall Score bloomz_abstract_without": "0.0",
    "precision_score bloomz_abstract_paraphrased_without": "1.0",
    "F1 score bloomz_abstract_paraphrased_without": "0.0",
    "Accuracy Score bloomz_abstract_paraphrased_without": "0.5",
    "Recall Score bloomz_abstract_paraphrased_without": "0.0",
    "precision_score llama3_abstract_without": "1.0",
    "F1 score llama3_abstract_without": "0.009950248756218905",
    "Accuracy Score llama3_abstract_without": "0.5025",
    "Recall Score llama3_abstract_without": "0.005",
    "precision_score cohere_abstract_without": "1.0",
    "F1 score cohere_abstract_without": "0.0",
    "Accuracy Score cohere_abstract_without": "0.5",
    "Recall Score cohere_abstract_without": "0.0",
    "precision_score davinci_abstract_without": "1.0",
    "F1 score davinci_abstract_without": "0.0033277870216306157",
    "Accuracy Score davinci_abstract_without": "0.5008333333333334",
    "Recall Score davinci_abstract_without": "0.0016666666666666668",
    "precision_score flant5_abstract_without": "1.0",
    "F1 score flant5_abstract_without": "0.1735159817351598",
    "Accuracy Score flant5_abstract_without": "0.5475",
    "Recall Score flant5_abstract_without": "0.095",
    "precision_score llama3_ml_without": "1.0",
    "F1 score llama3_ml_without": "0.0",
    "Accuracy Score llama3_ml_without": "0.5",
    "Recall Score llama3_ml_without": "0.0",
    "precision_score bloomz_wiki_without": "0.2",
    "F1 score bloomz_wiki_without": "0.006557377049180328",
    "Accuracy Score bloomz_wiki_without": "0.495",
    "Recall Score bloomz_wiki_without": "0.0033333333333333335",
    "precision_score chatgpt_wiki_without": "0.9919678714859438",
    "F1 score chatgpt_wiki_without": "0.9006381039197813",
    "Accuracy Score chatgpt_wiki_without": "0.9090150250417363",
    "Recall Score chatgpt_wiki_without": "0.8247078464106845",
    "precision_score cohere_wiki_without": "0.964769647696477",
    "F1 score cohere_wiki_without": "0.8506571087216248",
    "Accuracy Score cohere_wiki_without": "0.8664529914529915",
    "Recall Score cohere_wiki_without": "0.7606837606837606",
    "precision_score davinci_wiki_without": "0.9904306220095693",
    "F1 score davinci_wiki_without": "0.511742892459827",
    "Accuracy Score davinci_wiki_without": "0.6708333333333333",
    "Recall Score davinci_wiki_without": "0.345",
    "precision_score chatgptBloomz_abstract_without": "1.0",
    "F1 score chatgptBloomz_abstract_without": "0.0",
    "Accuracy Score chatgptBloomz_abstract_without": "0.5",
    "Recall Score chatgptBloomz_abstract_without": "0.0",
    "precision_score bloomzWiki_abstract_without": "0.2",
    "F1 score bloomzWiki_abstract_without": "0.003305785123966942",
    "Accuracy Score bloomzWiki_abstract_without": "0.4975",
    "Recall Score bloomzWiki_abstract_without": "0.0016666666666666668",
    "precision_score bloomzWikiML_abstract_without": "0.48",
    "F1 score bloomzWikiML_abstract_without": "0.01315068493150685",
    "Accuracy Score bloomzWikiML_abstract_without": "0.49972222222222223",
    "Recall Score bloomzWikiML_abstract_without": "0.006666666666666667"
}