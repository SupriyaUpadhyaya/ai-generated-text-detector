{
    "Model Type": "xgboost",
    "Task": "finetuneAndEval",
    "Training Data": "chatgpt",
    "Data Type": "abstract",
    "New Line": "with",
    "Log Folder Name": "xgboost_finetuneeval_with_chatgpt",
    "Title": "XGBoost Finetune and Evaluation - with - chatgpt",
    "percentage": null,
    "train": true,
    "Train input path": "data/with_n/arxiv_chatGPT_train.jsonl",
    "Test input path": "data/with_n/arxiv_chatGPT_test.jsonl",
    "Validation input path": "data/with_n/arxiv_chatGPT_validation.jsonl",
    "Human text column name": "human_text",
    "Machine text column name": "machine_text",
    "log_path": "results/report/xgboost/xgboost_finetuneeval_with_chatgpt/",
    "Training accuracy": 0.9258333333333333,
    "precision_score chatgpt_abstract_with": "0.886535552193646",
    "F1 score chatgpt_abstract_with": "0.929421094369548",
    "Accuracy Score chatgpt_abstract_with": "0.9258333333333333",
    "Recall Score chatgpt_abstract_with": "0.9766666666666667",
    "precision_score bloomz_abstract_with": "0.46846846846846846",
    "F1 score bloomz_abstract_with": "0.25304136253041365",
    "Accuracy Score bloomz_abstract_with": "0.48833333333333334",
    "Recall Score bloomz_abstract_with": "0.17333333333333334",
    "precision_score chatgpt_abstract_paraphrased_with": "0.886535552193646",
    "F1 score chatgpt_abstract_paraphrased_with": "0.929421094369548",
    "Accuracy Score chatgpt_abstract_paraphrased_with": "0.9258333333333333",
    "Recall Score chatgpt_abstract_paraphrased_with": "0.9766666666666667",
    "precision_score bloomz_abstract_paraphrased_with": "0.46846846846846846",
    "F1 score bloomz_abstract_paraphrased_with": "0.25304136253041365",
    "Accuracy Score bloomz_abstract_paraphrased_with": "0.48833333333333334",
    "Recall Score bloomz_abstract_paraphrased_with": "0.17333333333333334",
    "precision_score cohere_abstract_with": "0.7551724137931034",
    "F1 score cohere_abstract_with": "0.7423728813559322",
    "Accuracy Score cohere_abstract_with": "0.7466666666666667",
    "Recall Score cohere_abstract_with": "0.73",
    "precision_score davinci_abstract_with": "0.49158249158249157",
    "F1 score davinci_abstract_with": "0.3255295429208473",
    "Accuracy Score davinci_abstract_with": "0.49583333333333335",
    "Recall Score davinci_abstract_with": "0.24333333333333335",
    "precision_score flant5_abstract_with": "0.6495726495726496",
    "F1 score flant5_abstract_with": "0.4794952681388013",
    "Accuracy Score flant5_abstract_with": "0.5875",
    "Recall Score flant5_abstract_with": "0.38",
    "precision_score llama3_ml_with": "0.9195046439628483",
    "F1 score llama3_ml_with": "0.6435536294691224",
    "Accuracy Score llama3_ml_with": "0.7258333333333333",
    "Recall Score llama3_ml_with": "0.495",
    "precision_score bloomz_wiki_with": "0.05573248407643312",
    "F1 score bloomz_wiki_with": "0.057003257328990226",
    "Accuracy Score bloomz_wiki_with": "0.035",
    "Recall Score bloomz_wiki_with": "0.058333333333333334",
    "precision_score chatgpt_wiki_with": "0.0",
    "F1 score chatgpt_wiki_with": "0.0",
    "Accuracy Score chatgpt_wiki_with": "0.0",
    "Recall Score chatgpt_wiki_with": "0.0",
    "precision_score cohere_wiki_with": "0.0",
    "F1 score cohere_wiki_with": "0.0",
    "Accuracy Score cohere_wiki_with": "0.0",
    "Recall Score cohere_wiki_with": "0.0",
    "precision_score davinci_wiki_with": "0.0",
    "F1 score davinci_wiki_with": "0.0",
    "Accuracy Score davinci_wiki_with": "0.0",
    "Recall Score davinci_wiki_with": "0.0"
}