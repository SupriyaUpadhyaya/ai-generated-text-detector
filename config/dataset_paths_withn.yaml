chatgpt_abstract_with:
  train: "data/with_n/arxiv_chatGPT_train.jsonl"
  validation: "data/with_n/arxiv_chatGPT_validation.jsonl"
  test: "data/with_n/arxiv_chatGPT_test.jsonl"
  human_text_column: 'human_text'
  machine_text_column: 'machine_text'

bloomz_abstract_with:
  train: "data/with_n/arxiv_bloomz_train.jsonl"
  validation: "data/with_n/arxiv_bloomz_validation.jsonl"
  test: "data/with_n/arxiv_bloomz_test.jsonl"
  human_text_column: 'abstract'
  machine_text_column: 'machine_abstract'

chatgpt_abstract_paraphrased_with:
  train: "data/with_n/arxiv_chatGPT_paraphrased_train.jsonl"
  validation: "data/with_n/arxiv_chatGPT_paraphrased_validation.jsonl"
  test: "data/with_n/arxiv_chatGPT_paraphrased_test.jsonl"
  human_text_column: 'human_text'
  machine_text_column: 'machine_text'

bloomz_abstract_paraphrased_with:
  train: "data/with_n/arxiv_bloomz_paraphrased_train.jsonl"
  validation: "data/with_n/arxiv_bloomz_paraphrased_validation.jsonl"
  test: "data/with_n/arxiv_bloomz_paraphrased_test.jsonl"
  human_text_column: 'abstract'
  machine_text_column: 'machine_abstract'

# llama3_abstract_with:
#   train: "data/with_n/arxiv_llama3_train.jsonl"
#   validation: "data/with_n/arxiv_llama3_validation.jsonl"
#   test: "data/with_n/arxiv_llama3_test.jsonl"
#   human_text_column: 'abstract'
#   machine_text_column: 'machine_text'

cohere_abstract_with:
  train: "data/with_n/arxiv_cohere_train.jsonl"
  validation: "data/with_n/arxiv_cohere_validation.jsonl"
  test: "data/with_n/arxiv_cohere_test.jsonl"
  human_text_column: 'human_text'
  machine_text_column: 'machine_text'

davinci_abstract_with:
  train: "data/with_n/arxiv_davinci_train.jsonl"
  validation: "data/with_n/arxiv_davinci_validation.jsonl"
  test: "data/with_n/arxiv_davinci_test.jsonl"
  human_text_column: 'human_text'
  machine_text_column: 'machine_text'

flant5_abstract_with:
  train: "data/with_n/arxiv_flant5_train.jsonl"
  validation: "data/with_n/arxiv_flant5_validation.jsonl"
  test: "data/with_n/arxiv_flant5_test.jsonl"
  human_text_column: 'human_text'
  machine_text_column: 'machine_text'

llama3_ml_with:
  train: "data/ml/arxiv_papers_with_MT_llama_train.jsonl"
  validation: "data/ml/arxiv_papers_with_MT_llama_validation.jsonl"
  test: "data/ml/arxiv_papers_with_MT_llama_test.jsonl"
  human_text_column: 'Abstract'
  machine_text_column: 'machine_text'

bloomz_wiki_with:
  train: "data/wiki_processed/wikipedia_bloomz_train.jsonl"
  validation: "data/wiki_processed/wikipedia_bloomz_val.jsonl"
  test: "data/wiki_processed/wikipedia_bloomz_test.jsonl"
  human_text_column: 'text'
  machine_text_column: 'machine_abstract'

chatgpt_wiki_with:
  train: "data/wiki_processed/wikipedia_chatgpt_train.jsonl"
  validation: "data/wiki_processed/wikipedia_chatgpt_val.jsonl"
  test: "data/wiki_processed/wikipedia_chatgpt_test.jsonl"
  human_text_column: 'human_text'
  machine_text_column: 'machine_text'

cohere_wiki_with:
  train: "data/wiki_processed/wikipedia_cohere_train.jsonl"
  validation: "data/wiki_processed/wikipedia_cohere_val.jsonl"
  test: "data/wiki_processed/wikipedia_cohere_test.jsonl"
  human_text_column: 'human_text'
  machine_text_column: 'machine_text'

davinci_wiki_with:
  train: "data/wiki_processed/wikipedia_davinci_train.jsonl"
  validation: "data/wiki_processed/wikipedia_davinci_val.jsonl"
  test: "data/wiki_processed/wikipedia_davinci_test.jsonl"
  human_text_column: 'human_text'
  machine_text_column: 'machine_text'

# Continue for other trainData, dataType, and newLine combinations
